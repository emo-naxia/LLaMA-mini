# config.py

# 分词器文件夹路径（包含 vocab.txt / tokenizer.json）
TOKENIZER_PATH = "data/trained_tokenizer"

# 模型保存与加载路径
MODEL_PATH = "model_epoch23.pt"

# 分词器词表路径（注意：这里只在部分测试代码中可能会用到）
VOCAB_PATH = "data/trained_tokenizer/vocab.txt"